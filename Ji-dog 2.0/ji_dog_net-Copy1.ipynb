{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "75acd808-8187-4452-9f57-ec52fd472397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gym\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# from ji_dog_net_v1 import PPO_Clip\n",
    "# from ji_dog_net_v1 import ActorCritic_Clip\n",
    "# from ji_dog_net_v1 import process_state\n",
    "\n",
    "from ji_dog_net_v2 import PPO_Penalty\n",
    "from ji_dog_net_v2 import ActorCritic_Penalty\n",
    "\n",
    "from ji_dog_net_v3 import PPO_Clip\n",
    "from ji_dog_net_v3 import ActorCritic_Clip\n",
    "from ji_dog_net_v3 import process_state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f3836a-6b29-469c-bf79-7cb77672f023",
   "metadata": {},
   "source": [
    "## Check device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "05c5a862-f6b9-4cd5-923c-4d2ed509dd5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Device set to : NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "============================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"============================================================================================\")\n",
    "# set device to cpu or cuda\n",
    "device = torch.device('cpu')\n",
    "if(torch.cuda.is_available()): \n",
    "    device = torch.device('cuda:0') \n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"Device set to : \" + str(torch.cuda.get_device_name(device)))\n",
    "else:\n",
    "    print(\"Device set to : cpu\")\n",
    "print(\"============================================================================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6f026d-a1a8-4b35-84b6-eb95dadbb871",
   "metadata": {},
   "source": [
    "## Test ACNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "000f3284-c8fe-4914-aad9-be59a2cb2e3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "For unbatched 2-D input, hx and cx should also be 2-D but got (3-D, 3-D) tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m ppo \u001b[38;5;241m=\u001b[39m PPO_Clip(state_dim, action_dim, lr_actor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0003\u001b[39m, lr_critic\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m, gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.99\u001b[39m, K_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, eps_clip\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n\u001b[1;32m      5\u001b[0m state \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand((state_dim,))\u001b[38;5;241m.\u001b[39mto(device)  \n\u001b[0;32m----> 6\u001b[0m action, action_logprob, hidden_actor \u001b[38;5;241m=\u001b[39m \u001b[43mppo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAction output:\u001b[39m\u001b[38;5;124m\"\u001b[39m, action)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAction log probability:\u001b[39m\u001b[38;5;124m\"\u001b[39m, action_logprob)\n",
      "File \u001b[0;32m~/.local/share/ov/pkg/isaac-sim-4.2.0/Ji-dog 2.0/ji_dog_net_v3.py:63\u001b[0m, in \u001b[0;36mActorCritic_Clip.act\u001b[0;34m(self, state, hidden_actor)\u001b[0m\n\u001b[1;32m     61\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor_fc3(x))\n\u001b[1;32m     62\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Ensure correct dimensions for LSTM input\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m x, hidden_actor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactor_lstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_actor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Remove sequence dimension\u001b[39;00m\n\u001b[1;32m     66\u001b[0m action_mean \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor_activation(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor_fc4(x))\n",
      "File \u001b[0;32m~/.local/share/ov/pkg/isaac-sim-4.2.0/exts/omni.isaac.ml_archive/pip_prebundle/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/ov/pkg/isaac-sim-4.2.0/exts/omni.isaac.ml_archive/pip_prebundle/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/ov/pkg/isaac-sim-4.2.0/exts/omni.isaac.ml_archive/pip_prebundle/torch/nn/modules/rnn.py:909\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hx[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m hx[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    907\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor unbatched 2-D input, hx and cx should \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    908\u001b[0m                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malso be 2-D but got (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhx[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-D, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhx[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-D) tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 909\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg)\n\u001b[1;32m    910\u001b[0m     hx \u001b[38;5;241m=\u001b[39m (hx[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m), hx[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    911\u001b[0m \u001b[38;5;66;03m# Each batch of the hidden state should match the input sequence that\u001b[39;00m\n\u001b[1;32m    912\u001b[0m \u001b[38;5;66;03m# the user believes he/she is passing in.\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: For unbatched 2-D input, hx and cx should also be 2-D but got (3-D, 3-D) tensors"
     ]
    }
   ],
   "source": [
    "from torchviz import make_dot\n",
    "state_dim = 20  \n",
    "action_dim = 4 \n",
    "ppo = PPO_Clip(state_dim, action_dim, lr_actor=0.0003, lr_critic=0.001, gamma=0.99, K_epochs=4, eps_clip=0.2)\n",
    "state = torch.rand((state_dim,)).to(device)  \n",
    "action, action_logprob, hidden_actor = ppo.policy.act(state)\n",
    "\n",
    "print(\"Action output:\", action)\n",
    "print(\"Action log probability:\", action_logprob)\n",
    "\n",
    "state_value = ppo.policy.evaluate_critic(state)\n",
    "\n",
    "print(\"State value output:\", state_value)\n",
    "\n",
    "ppo.buffer.rewards.append(1.0)\n",
    "ppo.buffer.is_terminals.append(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f538080-d0d4-4c5c-ad89-c2685298155e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action output: tensor([[-0.3607, -0.1652, -0.7364,  0.0933]], device='cuda:0')\n",
      "Action log probability: tensor([-2.3997], device='cuda:0')\n",
      "State value output: tensor([-0.0140], device='cuda:0', grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from torchviz import make_dot\n",
    "state_dim = 20  \n",
    "action_dim = 4 \n",
    "ppo = PPO_Penalty(state_dim, action_dim, lr_actor=0.0003, lr_critic=0.001, gamma=0.99, K_epochs=4, eps_clip=0.2, kl_target=0.01, kl_penalty_coef=0.5, action_std_init=0.6)\n",
    "state = torch.rand((state_dim,)).to(device)  \n",
    "action, action_logprob, hidden_actor = ppo.policy.act(state)\n",
    "\n",
    "print(\"Action output:\", action)\n",
    "print(\"Action log probability:\", action_logprob)\n",
    "\n",
    "state_value = ppo.policy.evaluate_critic(state)\n",
    "\n",
    "print(\"State value output:\", state_value)\n",
    "\n",
    "ppo.buffer.rewards.append(1.0)\n",
    "ppo.buffer.is_terminals.append(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457a6739-84b9-4042-a8ba-305c34c2564c",
   "metadata": {},
   "source": [
    "## Train PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468faa10-37bc-4564-94c5-0f7445fbcf19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting kit application with the following args:  ['/home/bai/.local/share/ov/pkg/isaac-sim-4.2.0/exts/omni.isaac.kit/omni/isaac/kit/simulation_app.py', '/home/bai/.local/share/ov/pkg/isaac-sim-4.2.0/apps/omni.isaac.sim.python.kit', '--/app/tokens/exe-path=/home/bai/.local/share/ov/pkg/isaac-sim-4.2.0/kit', '--/persistent/app/viewport/displayOptions=3094', '--/rtx/materialDb/syncLoads=True', '--/rtx/hydra/materialSyncLoads=True', '--/omni.kit.plugin/syncUsdLoads=True', '--/app/renderer/resolution/width=1280', '--/app/renderer/resolution/height=720', '--/app/window/width=1440', '--/app/window/height=900', '--/renderer/multiGpu/enabled=True', '--/app/fastShutdown=False', '--ext-folder', '/home/bai/.local/share/ov/pkg/isaac-sim-4.2.0/exts', '--ext-folder', '/home/bai/.local/share/ov/pkg/isaac-sim-4.2.0/apps', '--/physics/cudaDevice=0', '--portable', '--no-window', '--/app/window/hideUi=1']\n",
      "Passing the following args to the base kit application:  ['-f', '/home/bai/.local/share/jupyter/runtime/kernel-bdd72e0d-7a3b-4388-8185-1bae18fa6855.json']\n",
      "[Warning] [omni.isaac.kit.simulation_app] fast shutdown not supported with jupyter notebooks\n",
      "[Info] [carb] Logging to file: /home/bai/.local/share/ov/pkg/isaac-sim-4.2.0/kit/logs/Kit/Isaac-Sim/4.2/kit_20241121_151055.log\n",
      "2024-11-21 07:10:55 [0ms] [Warning] [omni.kit.app.plugin] No crash reporter present, dumps uploading isn't available.\n",
      "[0.080s] [ext: omni.blobkey-1.1.2] startup\n",
      "[0.080s] [ext: omni.kit.async_engine-0.0.1] startup\n",
      "[0.343s] [ext: omni.stats-1.0.1] startup\n",
      "[0.344s] [ext: omni.datastore-0.0.0] startup\n",
      "[0.347s] [ext: omni.client-1.2.0] startup\n",
      "[0.364s] [ext: omni.ujitso.default-1.0.0] startup\n",
      "[0.364s] [ext: omni.gpu_foundation.shadercache.vulkan-1.0.0] startup\n",
      "[0.366s] [ext: omni.hsscclient-1.1.1] startup\n",
      "[0.366s] [ext: omni.assets.plugins-0.0.0] startup\n",
      "[0.367s] [ext: omni.gpu_foundation-0.0.0] startup\n",
      "[0.371s] [ext: carb.windowing.plugins-1.0.0] startup\n",
      "[0.375s] [ext: omni.kit.renderer.init-0.0.0] startup\n",
      "2024-11-21 07:10:56 [446ms] [Warning] [gpu.foundation.plugin] Skipping unsupported non-NVIDIA GPU: Intel(R) Graphics (RPL-P)\n",
      "2024-11-21 07:10:56 [446ms] [Warning] [gpu.foundation.plugin] Skipping unsupported non-NVIDIA GPU: Intel(R) Graphics (RPL-P)\n",
      "\n",
      "|---------------------------------------------------------------------------------------------|\n",
      "| Driver Version: 535.183.01    | Graphics API: Vulkan\n",
      "|=============================================================================================|\n",
      "| GPU | Name                             | Active | LDA | GPU Memory | Vendor-ID | LUID       |\n",
      "|     |                                  |        |     |            | Device-ID | UUID       |\n",
      "|     |                                  |        |     |            | Bus-ID    |            |\n",
      "|---------------------------------------------------------------------------------------------|\n",
      "| 0   | NVIDIA GeForce RTX 4060 Laptop.. | Yes: 0 |     | 8188    MB | 10de      | 0          |\n",
      "|     |                                  |        |     |            | 28e0      | 68c71b6b.. |\n",
      "|     |                                  |        |     |            | 1         |            |\n",
      "|---------------------------------------------------------------------------------------------|\n",
      "| 1   | Intel(R) Graphics (RPL-P)        |        |     | 23863   MB | 8086      | 0          |\n",
      "|     |                                  |        |     |            | a7a0      | 8680a0a7.. |\n",
      "|     |                                  |        |     |            | 0         |            |\n",
      "|=============================================================================================|\n",
      "| OS: 22.04.5 LTS (Jammy Jellyfish) ubuntu, Version: 22.04.5, Kernel: 6.8.0-49-generic\n",
      "| XServer Vendor: The X.Org Foundation, XServer Version: 12101004 (1.21.1.4)\n",
      "| Processor: 13th Gen Intel(R) Core(TM) i9-13900H | Cores: 14 | Logical: 28\n",
      "|---------------------------------------------------------------------------------------------|\n",
      "| Total Memory (MB): 31817 | Free Memory: 17957\n",
      "| Total Page/Swap (MB): 2047 | Free Page/Swap: 2047\n",
      "|---------------------------------------------------------------------------------------------|\n",
      "2024-11-21 07:10:56 [614ms] [Warning] [gpu.foundation.plugin] IOMMU is enabled.\n",
      "[0.772s] [ext: omni.kit.pipapi-0.0.0] startup\n",
      "[0.773s] [ext: omni.kit.pip_archive-0.0.0] startup\n",
      "[0.773s] [ext: omni.pip.compute-1.4.0] startup\n",
      "[0.773s] [ext: omni.pip.cloud-1.1.3] startup\n",
      "[0.775s] [ext: omni.isaac.core_archive-2.3.0] startup\n",
      "[0.775s] [ext: omni.materialx.libs-1.0.4] startup\n",
      "[0.781s] [ext: omni.isaac.ml_archive-2.0.1] startup\n",
      "[0.781s] [ext: omni.kit.telemetry-0.5.0] startup\n",
      "[0.804s] [ext: omni.usd.config-1.0.4] startup\n",
      "[0.807s] [ext: omni.gpucompute.plugins-0.0.0] startup\n",
      "[0.808s] [ext: omni.usd.libs-1.0.1] startup\n",
      "[0.888s] [ext: omni.iray.libs-0.0.0] startup\n",
      "[0.892s] [ext: omni.mdl.neuraylib-0.2.8] startup\n",
      "[0.893s] [ext: omni.mdl-55.0.1] startup\n",
      "[0.909s] [ext: omni.kit.usd.mdl-1.0.1] startup\n",
      "[1.008s] [ext: omni.kit.loop-isaac-1.2.0] startup\n",
      "[1.009s] [ext: omni.kit.test-1.1.0] startup\n",
      "[1.028s] [ext: omni.appwindow-1.1.8] startup\n",
      "[1.029s] [ext: omni.kit.renderer.core-1.0.2] startup\n",
      "[1.037s] [ext: omni.kit.renderer.capture-0.0.0] startup\n",
      "[1.038s] [ext: omni.kit.renderer.imgui-1.0.1] startup\n",
      "[1.085s] [ext: omni.ui-2.25.22] startup\n",
      "[1.094s] [ext: omni.kit.mainwindow-1.0.3] startup\n",
      "[1.095s] [ext: carb.audio-0.1.0] startup\n",
      "[1.098s] [ext: omni.uiaudio-1.0.0] startup\n",
      "[1.099s] [ext: omni.kit.uiapp-0.0.0] startup\n",
      "[1.099s] [ext: omni.usd.schema.isaac-2.1.0] startup\n",
      "[1.106s] [ext: omni.usd.schema.audio-0.0.0] startup\n",
      "[1.109s] [ext: omni.usd.schema.anim-0.0.0] startup\n",
      "[1.128s] [ext: omni.usd.schema.geospatial-0.0.0] startup\n",
      "[1.131s] [ext: omni.usd.schema.semantics-0.0.0] startup\n",
      "[1.133s] [ext: omni.usd.schema.omnigraph-1.0.0] startup\n",
      "[1.139s] [ext: omni.anim.navigation.schema-106.1.0] startup\n",
      "[1.141s] [ext: omni.usd.schema.scene.visualization-2.0.2] startup\n",
      "[1.142s] [ext: omni.usd.schema.omniscripting-1.0.0] startup\n",
      "[1.146s] [ext: omni.anim.graph.schema-106.1.0] startup\n",
      "[1.152s] [ext: omni.usd.schema.physx-106.1.9] startup\n",
      "[1.177s] [ext: omni.usd.schema.forcefield-106.1.9] startup\n",
      "[1.182s] [ext: omni.graph.exec-0.9.4] startup\n",
      "[1.182s] [ext: omni.kit.usd_undo-0.1.8] startup\n",
      "[1.183s] [ext: omni.kit.actions.core-1.0.0] startup\n",
      "[1.184s] [ext: omni.kit.exec.core-0.13.4] startup\n",
      "[1.186s] [ext: omni.usd_resolver-1.0.0] startup\n",
      "[1.189s] [ext: omni.kit.commands-1.4.9] startup\n",
      "[1.191s] [ext: omni.activity.core-1.0.1] startup\n",
      "[1.193s] [ext: omni.usd.core-1.4.1] startup\n",
      "[1.195s] [ext: omni.resourcemonitor-105.0.1] startup\n",
      "[1.196s] [ext: omni.kit.window.popup_dialog-2.0.24] startup\n",
      "[1.199s] [ext: omni.timeline-1.0.10] startup\n",
      "[1.200s] [ext: omni.kit.widget.nucleus_connector-1.1.9] startup\n",
      "[1.201s] [ext: usdrt.scenegraph-7.5.0] startup\n",
      "[1.233s] [ext: omni.kit.audiodeviceenum-1.0.1] startup\n",
      "[1.233s] [ext: omni.hydra.usdrt_delegate-7.5.1] startup\n",
      "[1.245s] [ext: omni.hydra.scene_delegate-0.3.3] startup\n",
      "[1.250s] [ext: omni.usd-1.12.2] startup\n",
      "[1.284s] [ext: omni.kit.menu.core-1.0.4] startup\n",
      "[1.285s] [ext: omni.kit.collaboration.telemetry-1.0.0] startup\n",
      "[1.285s] [ext: omni.kit.property.adapter.core-1.0.1] startup\n",
      "[1.287s] [ext: omni.kit.menu.utils-1.5.27] startup\n",
      "[1.292s] [ext: omni.kit.clipboard-1.0.4] startup\n",
      "[1.292s] [ext: omni.kit.collaboration.channel_manager-1.0.12] startup\n",
      "[1.293s] [ext: omni.kit.property.adapter.usd-1.0.1] startup\n",
      "[1.294s] [ext: omni.kit.widget.options_menu-1.1.6] startup\n",
      "[1.295s] [ext: omni.kit.widget.graph-1.12.15] startup\n",
      "[1.299s] [ext: omni.kit.widget.searchfield-1.1.8] startup\n",
      "[1.299s] [ext: omni.kit.widget.filter-1.1.4] startup\n",
      "[1.300s] [ext: omni.kit.property.adapter.fabric-1.0.1] startup\n",
      "[1.301s] [ext: omni.ui_query-1.1.4] startup\n",
      "[1.301s] [ext: omni.kit.window.extensions-1.4.11] startup\n",
      "[1.305s] [ext: omni.kit.usd.layers-2.1.36] startup\n",
      "[1.311s] [ext: omni.kit.widget.context_menu-1.2.2] startup\n",
      "[1.312s] [ext: omni.hydra.rtx.shadercache.vulkan-1.0.0] startup\n",
      "[1.313s] [ext: omni.kit.notification_manager-1.0.9] startup\n",
      "[1.314s] [ext: omni.kit.hotkeys.core-1.3.5] startup\n",
      "[1.314s] [ext: omni.kit.context_menu-1.8.1] startup\n",
      "[1.316s] [ext: omni.kit.widget.prompt-1.0.7] startup\n",
      "[1.316s] [ext: omni.kit.helper.file_utils-0.1.8] startup\n",
      "[1.317s] [ext: omni.kit.widget.nucleus_info-1.0.2] startup\n",
      "[1.317s] [ext: omni.kit.widget.filebrowser-2.10.51] startup\n",
      "[1.320s] [ext: omni.kit.search_core-1.0.5] startup\n",
      "[1.321s] [ext: omni.kit.widget.path_field-2.0.10] startup\n",
      "[1.321s] [ext: omni.ui.scene-1.10.3] startup\n",
      "[1.325s] [ext: omni.kit.widget.search_delegate-1.0.5] startup\n",
      "[1.325s] [ext: omni.kit.widget.options_button-1.0.3] startup\n",
      "[1.326s] [ext: omni.kit.widget.browser_bar-2.0.10] startup\n",
      "[1.326s] [ext: omni.volume-0.5.0] startup\n",
      "[1.329s] [ext: omni.kit.window.filepicker-2.10.40] startup\n",
      "[1.334s] [ext: omni.ujitso.processor.texture-1.0.0] startup\n",
      "[1.335s] [ext: omni.kit.window.file_exporter-1.0.30] startup\n",
      "[1.336s] [ext: omni.ujitso.client-0.0.0] startup\n",
      "[1.336s] [ext: omni.kit.widget.stage-2.11.2] startup\n",
      "[1.343s] [ext: omni.kit.widget.live_session_management.ui-1.0.1] startup\n",
      "[1.345s] [ext: omni.kit.collaboration.presence_layer-1.0.9] startup\n",
      "[1.347s] [ext: omni.hydra.rtx-1.0.0] startup\n",
      "[1.362s] [ext: omni.inspect-1.0.1] startup\n",
      "[1.363s] [ext: omni.kit.widget.searchable_combobox-1.0.6] startup\n",
      "[1.364s] [ext: omni.kit.window.file_importer-1.1.12] startup\n",
      "[1.365s] [ext: omni.kit.stage_template.core-1.1.22] startup\n",
      "[1.365s] [ext: omni.kit.widget.settings-1.2.2] startup\n",
      "[1.366s] [ext: omni.kit.window.file-1.3.54] startup\n",
      "[1.368s] [ext: omni.kit.window.drop_support-1.0.3] startup\n",
      "[1.369s] [ext: omni.kit.window.content_browser_registry-0.0.6] startup\n",
      "[1.369s] [ext: omni.kit.window.preferences-1.6.0] startup\n",
      "[1.374s] [ext: omni.kit.window.content_browser-2.9.18] startup\n",
      "[1.384s] [ext: omni.kit.widget.live_session_management-1.2.20] startup\n",
      "[1.385s] [ext: omni.kit.widget.text_editor-1.0.2] startup\n",
      "[1.386s] [ext: omni.kit.hydra_texture-1.3.9] startup\n",
      "[1.389s] [ext: omni.kit.viewport.legacy_gizmos-1.1.0] startup\n",
      "[1.391s] [ext: omni.kit.raycast.query-1.0.5] startup\n",
      "[1.396s] [ext: omni.kit.material.library-1.5.6] startup\n",
      "[1.401s] [ext: omni.kit.widget.viewport-106.1.0] startup\n",
      "[1.404s] [ext: omni.kit.viewport.registry-104.0.6] startup\n",
      "[1.404s] [ext: omni.hydra.engine.stats-1.0.2] startup\n",
      "[1.407s] [ext: omni.kit.widget.highlight_label-1.0.2] startup\n",
      "[1.407s] [ext: omni.kit.viewport.window-107.0.6] startup\n",
      "[1.421s] [ext: omni.kit.window.property-1.11.3] startup\n",
      "[1.422s] [ext: omni.graph.core-2.179.2] startup\n",
      "[1.424s] [ext: omni.graph.tools-1.79.0] startup\n",
      "[1.440s] [ext: omni.kit.viewport.utility-1.0.17] startup\n",
      "[1.440s] [ext: omni.kit.property.usd-4.2.8] startup\n",
      "[1.446s] [ext: omni.debugdraw-0.1.3] startup\n",
      "[1.449s] [ext: omni.graph-1.140.0] startup\n",
      "[1.481s] [ext: omni.graph.ui-1.70.2] startup\n",
      "[1.494s] [ext: omni.kvdb-106.1.9] startup\n",
      "[1.496s] [ext: omni.graph.image.core-0.4.5] startup\n",
      "[1.498s] [ext: omni.localcache-106.1.9] startup\n",
      "[1.499s] [ext: omni.graph.image.nodes-1.1.0] startup\n",
      "[1.502s] [ext: omni.usdphysics-106.1.9] startup\n",
      "[1.506s] [ext: omni.physx.foundation-106.1.9] startup\n",
      "[1.507s] [ext: omni.convexdecomposition-106.1.9] startup\n",
      "[1.512s] [ext: omni.graph.nodes-1.146.1] startup\n",
      "[1.519s] [ext: omni.physx.cooking-106.1.9] startup\n",
      "[1.529s] [ext: omni.kit.primitive.mesh-1.0.17] startup\n",
      "[1.532s] [ext: omni.physx-106.1.9] startup\n",
      "[1.543s] [ext: omni.kit.stage_templates-1.2.5] startup\n",
      "[1.545s] [ext: omni.isaac.version-1.1.0] startup\n",
      "[1.546s] [ext: omni.kit.widget.material_preview-1.0.16] startup\n",
      "[1.547s] [ext: omni.isaac.nucleus-0.3.1] startup\n",
      "[1.548s] [ext: omni.physics.tensors-106.1.9] startup\n",
      "[1.558s] [ext: omni.physx.stageupdate-106.1.9] startup\n",
      "[1.560s] [ext: omni.graph.action_core-1.1.6] startup\n",
      "[1.564s] [ext: omni.warp.core-1.2.1] startup\n",
      "[1.631s] [ext: omni.physx.tensors-106.1.9] startup\n",
      "[1.636s] [ext: omni.graph.scriptnode-1.20.1] startup\n",
      "[1.637s] [ext: omni.kit.manipulator.viewport-107.0.0] startup\n",
      "[1.639s] [ext: omni.graph.action_nodes-1.24.0] startup\n",
      "[1.645s] [ext: omni.kit.ui_test-1.3.2] startup\n",
      "[1.648s] [ext: omni.isaac.core-3.19.5] startup\n",
      "[1.897s] [ext: omni.graph.visualization.nodes-2.1.1] startup\n",
      "[1.903s] [ext: omni.graph.action-1.102.1] startup\n",
      "[1.904s] [ext: omni.kit.window.cursor-1.1.2] startup\n",
      "[1.908s] [ext: omni.isaac.ui-0.16.0] startup\n",
      "[1.911s] [ext: omni.kit.viewport.menubar.core-106.1.0] startup\n",
      "[1.925s] [ext: omni.kit.graph.delegate.default-1.2.2] startup\n",
      "[1.926s] [ext: omni.syntheticdata-0.6.9] startup\n",
      "[1.946s] [ext: omni.kit.graph.usd.commands-1.3.1] startup\n",
      "[1.948s] [ext: omni.kit.graph.editor.core-1.5.3] startup\n",
      "[1.953s] [ext: omni.kit.numpy.common-0.1.2] startup\n",
      "[1.954s] [ext: omni.warp-1.2.1] startup\n",
      "[1.958s] [ext: omni.kit.window.material_graph-1.8.18] startup\n",
      "[2.011s] [ext: omni.isaac.dynamic_control-1.3.8] startup\n",
      "[2.025s] [ext: omni.replicator.core-1.11.20] startup\n",
      "2024-11-21 07:10:57 [1,989ms] [Warning] [omni.replicator.core.scripts.annotators] Annotator PostProcessDispatch is already registered, overwriting annotator template\n",
      "Warp 1.2.1 initialized:\n",
      "   CUDA Toolkit 11.8, Driver 12.2\n",
      "   Devices:\n",
      "     \"cpu\"      : \"x86_64\"\n",
      "     \"cuda:0\"   : \"NVIDIA GeForce RTX 4060 Laptop GPU\" (8 GiB, sm_89, mempool enabled)\n",
      "   Kernel cache:\n",
      "     /home/bai/.cache/warp/1.2.1\n",
      "[2.132s] [ext: omni.isaac.lula-3.0.1] startup\n",
      "[2.139s] [ext: omni.isaac.surface_gripper-1.0.1] startup\n",
      "[2.143s] [ext: omni.isaac.core_nodes-1.16.3] startup\n",
      "[2.158s] [ext: omni.isaac.motion_generation-7.1.0] startup\n",
      "[2.171s] [ext: omni.isaac.manipulators-2.1.0] startup\n",
      "[2.174s] [ext: omni.isaac.franka-0.4.1] startup\n",
      "[2.180s] [ext: omni.kit.graph.widget.variables-2.1.0] startup\n",
      "[2.182s] [ext: omni.kit.graph.delegate.modern-1.10.6] startup\n",
      "[2.194s] [ext: omni.isaac.cortex-0.3.9] startup\n",
      "[2.198s] [ext: omni.graph.window.core-1.113.1] startup\n",
      "[2.232s] [ext: omni.isaac.wheeled_robots-2.3.3] startup\n",
      "[2.245s] [ext: omni.isaac.cortex.sample_behaviors-1.0.6] startup\n",
      "[2.247s] [ext: omni.graph.window.generic-1.26.0] startup\n",
      "[2.258s] [ext: omni.isaac.menu-0.7.3] startup\n",
      "[2.264s] [ext: omni.kit.widget.live-2.1.8] startup\n",
      "[2.270s] [ext: omni.kit.actions.window-1.1.1] startup\n",
      "[2.283s] [ext: omni.kit.widget.cache_indicator-2.0.10] startup\n",
      "[2.355s] [ext: omni.kit.hotkeys.window-1.4.5] startup\n",
      "2024-11-21 07:10:57 [2,295ms] [Warning] [omni.kit.widget.cache_indicator.cache_state_menu] Unable to detect Omniverse Cache Server. Consider installing it for better IO performance.\n",
      "[2.364s] [ext: omni.kit.ui.actions-1.0.2] startup\n",
      "[2.366s] [ext: omni.kit.widget.stage_icons-1.0.5] startup\n",
      "[2.368s] [ext: omni.kit.menu.common-1.1.7] startup\n",
      "[2.370s] [ext: omni.kit.selection-0.1.4] startup\n",
      "[2.375s] [ext: omni.isaac.kit-1.13.2] startup\n",
      "[2.375s] [ext: omni.isaac.block_world-1.0.0] startup\n",
      "[2.380s] [ext: omni.kit.window.stage-2.5.10] startup\n",
      "[2.388s] [ext: omni.isaac.debug_draw-1.1.0] startup\n",
      "[2.392s] [ext: omni.kit.menu.edit-1.1.24] startup\n",
      "[2.397s] [ext: omni.kit.menu.file-1.1.14] startup\n",
      "[2.398s] [ext: omni.kit.profiler.window-2.2.3] startup\n",
      "[2.403s] [ext: omni.kit.menu.stage-1.2.5] startup\n",
      "[2.404s] [ext: omni.isaac.occupancy_map-1.0.3] startup\n",
      "[2.409s] [ext: omni.importer.mjcf-1.1.1] startup\n",
      "[2.419s] [ext: omni.graph.window.action-1.28.0] startup\n",
      "[2.427s] [ext: omni.kit.property.camera-1.0.8] startup\n",
      "[2.429s] [ext: omni.kit.property.light-1.0.10] startup\n",
      "[2.430s] [ext: omni.kit.property.geometry-1.3.1] startup\n",
      "[2.433s] [ext: omni.hydra.scene_api-0.1.2] startup\n",
      "[2.438s] [ext: omni.kit.property.audio-1.0.14] startup\n",
      "[2.441s] [ext: omni.kit.property.render-1.1.2] startup\n",
      "[2.443s] [ext: omni.kit.property.transform-1.5.9] startup\n",
      "[2.446s] [ext: omni.kit.property.material-1.10.8] startup\n",
      "[2.450s] [ext: omni.kit.widget.layers-1.8.0] startup\n",
      "[2.457s] [ext: omni.kit.property.isaac-0.2.3] startup\n",
      "[2.459s] [ext: omni.kit.property.bundle-1.3.1] startup\n",
      "[2.460s] [ext: omni.sensors.nv.common-1.2.2-isaac-1] startup\n",
      "[2.469s] [ext: omni.kit.property.layer-1.1.8] startup\n",
      "[2.471s] [ext: omni.kit.stage_column.payload-2.0.0] startup\n",
      "[2.472s] [ext: omni.isaac.scene_blox-0.1.2] startup\n",
      "[2.473s] [ext: omni.sensors.nv.materials-1.2.1-isaac-1] startup\n",
      "[2.474s] [ext: omni.sensors.nv.wpm-1.2.1-isaac-1] startup\n",
      "[2.475s] [ext: omni.kit.viewport.actions-106.0.2] startup\n",
      "[2.479s] [ext: omni.sensors.nv.lidar-1.2.2-isaac-1] startup\n",
      "[2.483s] [ext: omni.sensors.nv.radar-1.2.1-isaac-1] startup\n",
      "[2.488s] [ext: omni.kit.viewport.menubar.display-107.0.2] startup\n",
      "[2.489s] [ext: omni.kit.manipulator.transform-104.7.4] startup\n",
      "[2.492s] [ext: omni.kit.widget.toolbar-1.7.2] startup\n",
      "[2.497s] [ext: omni.sensors.tiled-0.0.6] startup\n",
      "[2.500s] [ext: omni.sensors.nv.ids-1.1.0-isaac-1] startup\n",
      "[2.504s] [ext: omni.isaac.range_sensor-3.1.2] startup\n",
      "[2.514s] [ext: omni.usdphysics.ui-106.1.9] startup\n",
      "[2.534s] [ext: omni.physx.commands-106.1.9] startup\n",
      "[2.537s] [ext: omni.kit.manipulator.tool.snap-1.5.11] startup\n",
      "[2.541s] [ext: omni.isaac.sensor-12.9.1] startup\n",
      "[2.594s] [ext: omni.kit.manipulator.selector-1.1.1] startup\n",
      "[2.597s] [ext: omni.physx.ui-106.1.9] startup\n",
      "[2.628s] [ext: omni.isaac.quadruped-2.0.1] startup\n",
      "[2.635s] [ext: omni.kit.viewport.manipulator.transform-107.0.2] startup\n",
      "[2.639s] [ext: omni.physx.demos-106.1.9] startup\n",
      "[2.657s] [ext: omni.kit.property.physx-106.1.9] startup\n",
      "[2.713s] [ext: omni.kit.widget.calendar-1.0.8] startup\n",
      "[2.716s] [ext: omni.kit.manipulator.prim.core-107.0.4] startup\n",
      "[2.720s] [ext: omni.fabric.commands-1.1.5] startup\n",
      "[2.723s] [ext: omni.physx.vehicle-106.1.9] startup\n",
      "[2.737s] [ext: omni.kit.widget.extended_searchfield-1.0.28] startup\n",
      "[2.743s] [ext: omni.kit.manipulator.prim.fabric-107.0.3] startup\n",
      "[2.745s] [ext: omni.kit.manipulator.prim.usd-107.0.2] startup\n",
      "[2.747s] [ext: omni.kit.widget.timeline-105.0.1] startup\n",
      "[2.749s] [ext: omni.kit.window.commands-0.2.6] startup\n",
      "[2.750s] [ext: omni.physx.camera-106.1.9] startup\n",
      "[2.760s] [ext: omni.kit.manipulator.camera-105.0.5] startup\n",
      "[2.763s] [ext: omni.kit.viewport.menubar.camera-107.0.2] startup\n",
      "[2.767s] [ext: omni.kit.manipulator.prim-107.0.0] startup\n",
      "[2.768s] [ext: omni.kit.manipulator.selection-106.0.1] startup\n",
      "[2.768s] [ext: omni.kit.window.toolbar-1.6.1] startup\n",
      "[2.771s] [ext: omni.kit.stage_column.variant-1.0.13] startup\n",
      "[2.771s] [ext: omni.kit.viewport.menubar.render-106.1.1] startup\n",
      "[2.774s] [ext: omni.kit.viewport.menubar.settings-107.0.3] startup\n",
      "[2.778s] [ext: omni.physx.cct-106.1.9] startup\n",
      "[2.788s] [ext: omni.physx.graph-106.1.9] startup\n",
      "[2.804s] [ext: omni.physx.supportui-106.1.9] startup\n",
      "[2.825s] [ext: omni.physx.telemetry-106.1.9] startup\n",
      "[2.828s] [ext: omni.graph.ui_nodes-1.26.0] startup\n",
      "[2.832s] [ext: omni.kit.viewport.bundle-104.0.1] startup\n",
      "[2.833s] [ext: omni.isaac.universal_robots-0.3.5] startup\n",
      "[2.834s] [ext: omni.kit.window.console-0.2.13] startup\n",
      "[2.843s] [ext: omni.kit.window.script_editor-1.7.6] startup\n",
      "[2.845s] [ext: omni.kit.menu.create-1.0.16] startup\n",
      "[2.847s] [ext: omni.graph.bundle.action-2.4.1] startup\n",
      "[2.848s] [ext: omni.physx.bundle-106.1.9] startup\n",
      "[2.849s] [ext: omni.rtx.window.settings-0.6.17] startup\n",
      "[2.854s] [ext: omni.kit.window.status_bar-0.1.7] startup\n",
      "[2.859s] [ext: omni.kit.window.title-1.1.5] startup\n",
      "[2.861s] [ext: omni.replicator.isaac-1.15.2] startup\n",
      "[2.877s] [ext: omni.replicator.replicator_yaml-2.0.6] startup\n",
      "[2.898s] [ext: omni.rtx.settings.core-0.6.3] startup\n",
      "[2.916s] [ext: omni.kit.viewport.menubar.lighting-106.0.2] startup\n",
      "[2.927s] [ext: semantics.schema.editor-0.3.8] startup\n",
      "[2.937s] [ext: semantics.schema.property-1.0.4] startup\n",
      "[2.943s] [ext: omni.kit.viewport.rtx-104.0.1] startup\n",
      "[2.943s] [ext: omni.isaac.utils-1.0.1] startup\n",
      "[2.946s] [ext: omni.isaac.cloner-0.8.1] startup\n",
      "[2.949s] [ext: omni.importer.urdf-1.14.1] startup\n",
      "[2.984s] [ext: omni.kit.window.stats-0.1.6] startup\n",
      "[2.989s] [ext: omni.isaac.sim.python-4.2.0] startup\n",
      "[2.991s] Simulation App Starting\n",
      "[4.309s] app ready\n",
      "[4.807s] Simulation App Startup Complete\n",
      "Robot articulation successfully loaded: <omni.isaac.core.robots.robot.Robot object at 0x7b3e00d6b790>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:   0%|                    | 1/1000 [01:25<23:51:27, 85.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 completed with reward: 0.10673717461574717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:   1%|▏                  | 11/1000 [15:25<22:50:42, 83.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 10 completed with reward: 0.10673708692514494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:   2%|▍                  | 21/1000 [29:03<22:15:36, 81.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 20 completed with reward: 0.1067370769381989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:   3%|▌                  | 31/1000 [42:43<22:07:37, 82.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 30 completed with reward: 0.10673692716258798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:   4%|▊                  | 41/1000 [56:35<22:18:22, 83.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 40 completed with reward: 0.10673701936320346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:   5%|▊                | 51/1000 [1:11:35<24:44:20, 93.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 50 completed with reward: 0.10673704983409305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:   6%|█                | 61/1000 [1:27:12<24:39:56, 94.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 60 completed with reward: 0.10673714519715749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:   7%|█▏               | 71/1000 [1:43:05<24:36:03, 95.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 70 completed with reward: 0.10673699485442423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:   8%|█▍               | 81/1000 [1:58:50<23:56:45, 93.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 80 completed with reward: 0.10673705673446099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:   9%|█▌               | 91/1000 [2:14:22<23:31:32, 93.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 90 completed with reward: 0.10673698966698875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  10%|█▌             | 101/1000 [2:31:00<26:24:44, 105.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100 completed with reward: 0.10673696127800236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  11%|█▋             | 111/1000 [2:49:15<26:45:38, 108.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 110 completed with reward: 0.10673710704188477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  12%|█▉              | 121/1000 [3:04:50<23:02:32, 94.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 120 completed with reward: 0.10673711137843833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  13%|██              | 131/1000 [3:20:38<23:02:24, 95.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 130 completed with reward: 0.10673704921500882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  13%|██              | 132/1000 [3:22:14<23:01:55, 95.52s/it]"
     ]
    }
   ],
   "source": [
    "# Environment and simulation setup\n",
    "from isaacsim import SimulationApp\n",
    "simulation_app = SimulationApp({\"headless\": True})\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from ji_dog_env_create import Ji_Dog_Env\n",
    "from tqdm import tqdm  \n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    script_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    relative_path = \"Ji-dog 2.0/Model(including video)/ji_dog1.0.usd\"\n",
    "    usd_path = os.path.join(script_dir, relative_path)\n",
    "    env = Ji_Dog_Env('usd_path')\n",
    "    state_dim = 20\n",
    "    action_dim = 4\n",
    "    max_training_timesteps = 1000\n",
    "    max_timesteps = 5000\n",
    "    ppo = PPO_Clip(state_dim, action_dim, lr_actor=0.0003, lr_critic=0.001, gamma=0.99, K_epochs=4, eps_clip=0.2)\n",
    "\n",
    "    # Initialize \n",
    "    writer = SummaryWriter(log_dir=\"runs/Ji_Dog_Training1\")\n",
    "\n",
    "    for episode in tqdm(range(max_training_timesteps), desc=\"Training Episodes\"):\n",
    "        state = env.reset()\n",
    "        state = process_state(state)\n",
    "        state = np.array(state)\n",
    "        episode_reward = 0\n",
    "        for t in range(max_timesteps + 1):\n",
    "            action = ppo.select_action(state)\n",
    "            state, reward, done, _ = env.step(action[0])\n",
    "            state = process_state(state)\n",
    "            state = np.array(state)\n",
    "            ppo.buffer.rewards.append(reward)\n",
    "            ppo.buffer.is_terminals.append(done)\n",
    "            episode_reward = episode_reward + reward\n",
    "            if done:\n",
    "                break\n",
    "                    \n",
    "        # Update PPO and record metrics\n",
    "        average_loss, policy_loss, value_loss, policy_entropy = ppo.update()\n",
    "        \n",
    "        # Log metrics to TensorBoard\n",
    "        writer.add_scalar(\"Average Loss\", average_loss, episode)\n",
    "        writer.add_scalar(\"Policy Entropy\", policy_entropy, episode)\n",
    "        writer.add_scalar(\"Value Loss\", value_loss, episode)\n",
    "        writer.add_scalar(\"Policy Loss\", policy_loss, episode)\n",
    "        writer.add_scalar(\"Episode Reward\", episode_reward, episode)\n",
    "        \n",
    "        if episode % 10 == 0:\n",
    "            print(f\"Episode {episode} completed with reward: {episode_reward}\")\n",
    "\n",
    "    writer.close()\n",
    "\n",
    "save_path = \"Model_Checkpoints/Ji_dog_{}_Episode.pth\".format('2.0')\n",
    "print(\"save checkpoint path : \" + save_path)\n",
    "ppo.save(save_path)\n",
    "print('Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef3f42b-7328-4388-a525-bbd342e51227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment and simulation setup\n",
    "from isaacsim import SimulationApp\n",
    "simulation_app = SimulationApp({\"headless\": True})\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from ji_dog_env_create import Ji_Dog_Env\n",
    "from tqdm import tqdm  \n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    script_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    relative_path = \"Ji-dog 2.0/Model(including video)/ji_dog1.0.usd\"\n",
    "    usd_path = os.path.join(script_dir, relative_path)\n",
    "    env = Ji_Dog_Env('usd_path')\n",
    "    state_dim = 20\n",
    "    action_dim = 4\n",
    "    max_training_timesteps = 1000\n",
    "    max_timesteps = 5000\n",
    "    ppo = PPO_Clip(state_dim, action_dim, lr_actor=0.0003, lr_critic=0.001, gamma=0.99, K_epochs=4, eps_clip=0.2)\n",
    "\n",
    "    # Initialize \n",
    "    writer = SummaryWriter(log_dir=\"runs/Ji_Dog_Training1\")\n",
    "\n",
    "    for episode in tqdm(range(max_training_timesteps), desc=\"Training Episodes\"):\n",
    "        total_rewards = {\n",
    "            \"distance_reward\": 0,\n",
    "            \"fall_penalty\": 0,\n",
    "            \"symmetry_reward\": 0,\n",
    "            \"period_penalty\": 0,\n",
    "            \"contact_penalty\": 0,\n",
    "            \"smoothness_penalty\": 0,\n",
    "        }\n",
    "        \n",
    "        state = env.reset()\n",
    "        state = process_state(state)\n",
    "        state = np.array(state)\n",
    "        \n",
    "        total_episode_reward = 0\n",
    "        for t in range(max_timesteps + 1):\n",
    "            action = ppo.select_action(state)\n",
    "            state, reward, done, _ = env.step(action[0])\n",
    "\n",
    "            total_reward, reward_contributions = env.calculate_reward()\n",
    "            for key in reward_contributions:\n",
    "                total_rewards[key] += reward_contributions[key]\n",
    "                \n",
    "            state = process_state(state)\n",
    "            state = np.array(state)\n",
    "            ppo.buffer.rewards.append(reward)\n",
    "            ppo.buffer.is_terminals.append(done)\n",
    "            total_episode_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "                    \n",
    "        # Update PPO and record metrics\n",
    "        average_loss, policy_loss, value_loss, policy_entropy = ppo.update()\n",
    "        \n",
    "        # Log metrics to TensorBoard\n",
    "        writer.add_scalar(\"Average Loss\", average_loss, episode)\n",
    "        writer.add_scalar(\"Policy Entropy\", policy_entropy, episode)\n",
    "        writer.add_scalar(\"Value Loss\", value_loss, episode)\n",
    "        writer.add_scalar(\"Policy Loss\", policy_loss, episode)\n",
    "        \n",
    "        for key, value in total_rewards.items():\n",
    "            writer.add_scalar(f\"Rewards/{key}\", value, episode)\n",
    "    \n",
    "        writer.add_scalar(\"Episode Total Reward\", total_episode_reward, episode)\n",
    "        if episode % 10 == 0:\n",
    "            print(f\"Episode {episode} completed with reward: {episode_reward}\")\n",
    "    \n",
    "    writer.close()\n",
    "\n",
    "\n",
    "save_path = \"Model_Checkpoints/Ji_dog_{}_Episode.pth\".format('2.0')\n",
    "print(\"save checkpoint path : \" + save_path)\n",
    "ppo.save(save_path)\n",
    "print('Finished!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ded4bd-c3d5-462d-82a0-fe7fc13e8622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "load_path = \"Model_Checkpoints/Ji_dog_1.0_Episode.pth\"\n",
    "ppo = PPO_Clip(state_dim, action_dim, lr_actor=0.0003, lr_critic=0.001, gamma=0.99, K_epochs=4, eps_clip=0.2)\n",
    "ppo.load(load_path)\n",
    "\n",
    "\n",
    "env = Ji_Dog_Env('/home/bai/.local/share/ov/pkg/isaac-sim-4.2.0/Ji-dog 2.0/Model(including video)/ji_dog1.0.usd')\n",
    "state_dim = 20\n",
    "action_dim = 4\n",
    "max_training_timesteps = 100\n",
    "max_timesteps = 500\n",
    "ppo = PPO_Clip(state_dim, action_dim, lr_actor=0.0003, lr_critic=0.001, gamma=0.99, K_epochs=4, eps_clip=0.2)\n",
    "\n",
    "# Initialize \n",
    "writer = SummaryWriter(log_dir=\"runs/Ji_Dog_Training\")\n",
    "\n",
    "\n",
    "state = env.reset()\n",
    "state = process_state(state)\n",
    "state = np.array(state)\n",
    "\n",
    "for t in range(max_timesteps + 1):\n",
    "    action = ppo.select_action(state)\n",
    "    state, reward, done, _ = env.step(action[0])\n",
    "    state = process_state(state)\n",
    "    state = np.array(state)\n",
    "    ppo.buffer.rewards.append(reward)\n",
    "    ppo.buffer.is_terminals.append(done)\n",
    "\n",
    "    if done:\n",
    "        break\n",
    "            \n",
    "# Update PPO and record metrics\n",
    "average_loss, policy_loss, value_loss, policy_entropy = ppo.update()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de8eb280-4e21-4f94-9841-2ad3ced03b42",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'simulation_app' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msimulation_app\u001b[49m\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'simulation_app' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "simulation_app.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7f8cb9-5a88-4fc3-9165-c4424c652a7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6422a160-ba59-4ad6-b605-b8efcf1977e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Isaac Sim Python 3",
   "language": "python",
   "name": "isaac_sim_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
